require("dotenv").config();
const axios = require("axios");
const { createClient } = require("@supabase/supabase-js");

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// INIT SUPABASE
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIG
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TABLE  = "image_concept_phase_final";
const BUCKET = "feed-posts";          // change if you want a new bucket
const FOLDER = "image-concept";       // folder inside bucket
const LIMIT  = 20;

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// DOWNLOAD IMAGE
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function downloadImage(url) {
  try {
    const response = await axios.get(url, {
      responseType: "arraybuffer",
      timeout: 20000,
    });
    return Buffer.from(response.data);
  } catch (err) {
    console.error("âŒ Download failed:", url, err.message);
    return null;
  }
}

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// MAIN WORKER
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function startWorker() {
  console.log("ğŸš€ image_concept_phase_final â†’ Supabase image migration started");

  const { data: rows, error } = await supabase
    .from(TABLE)
    .select("id, image_url")
    .not("image_url", "is", null)
    .is("supabase_image_url", null)
    .limit(LIMIT);

  if (error) {
    console.error("âŒ DB fetch error:", error);
    process.exit(1);
  }

  console.log(`ğŸ“Œ ${rows.length} rows found`);

  for (const row of rows) {
    console.log(`â¡ï¸ Processing row: ${row.id}`);

    if (!row.image_url || row.image_url.trim() === "") {
      console.log("âš ï¸ Empty image_url, skipped");
      continue;
    }

    const buffer = await downloadImage(row.image_url);
    if (!buffer) {
      console.log("âš ï¸ Image download failed, skipped");
      continue;
    }

    // STORAGE PATH
    const fileName = `${row.id}-${Date.now()}.jpg`;
    const storagePath = `${FOLDER}/${fileName}`;

    // UPLOAD
    const { error: uploadErr } = await supabase.storage
      .from(BUCKET)
      .upload(storagePath, buffer, {
        contentType: "image/jpeg",
        upsert: false,
      });

    if (uploadErr) {
      console.error("âŒ Upload failed:", uploadErr);
      continue;
    }

    // PUBLIC URL
    const { data: publicUrl } = supabase.storage
      .from(BUCKET)
      .getPublicUrl(storagePath);

    const newUrl = publicUrl.publicUrl;

    // UPDATE TABLE
    const { error: updateErr } = await supabase
      .from(TABLE)
      .update({ supabase_image_url: newUrl })
      .eq("id", row.id);

    if (updateErr) {
      console.error("âŒ Update failed:", updateErr);
      continue;
    }

    console.log(`âœ… Migrated: ${row.id}`);
  }

  console.log("ğŸ‰ Migration batch complete");
  process.exit(0);
}

startWorker();

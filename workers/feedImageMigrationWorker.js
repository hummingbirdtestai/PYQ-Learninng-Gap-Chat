require("dotenv").config();
const axios = require("axios");
const { createClient } = require("@supabase/supabase-js");

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// INIT SUPABASE
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIG
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TABLE  = "image_concept_phase_final";
const BUCKET = "feed-posts";          // change if you want a new bucket
const FOLDER = "image-concept";       // folder inside bucket
const LIMIT  = 20;

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// DOWNLOAD IMAGE
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function downloadImage(url) {
  try {
    const response = await axios.get(url, {
      responseType: "arraybuffer",
      timeout: 20000,
    });
    return Buffer.from(response.data);
  } catch (err) {
    console.error("âŒ Download failed:", url, err.message);
    return null;
  }
}

//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// MAIN WORKER
//â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function startWorker() {
  console.log("ğŸš€ image_concept_phase_final â†’ Supabase image migration started");

  while (true) {
    const { data: rows, error } = await supabase
      .from(TABLE)
      .select("id, image_url")
      .not("image_url", "is", null)
      .is("supabase_image_url", null)
      .limit(LIMIT);

    if (error) {
      console.error("âŒ DB fetch error:", error);
      await sleep(2000);
      continue;
    }

    if (!rows.length) {
      console.log("â¸ï¸ No rows left, sleeping...");
      await sleep(3000);
      continue;
    }

    console.log(`ğŸ“Œ ${rows.length} rows found`);

    for (const row of rows) {
      console.log(`â¡ï¸ Processing row: ${row.id}`);

      const buffer = await downloadImage(row.image_url);
      if (!buffer) continue;

      const fileName = `${row.id}-${Date.now()}.jpg`;
      const storagePath = `${FOLDER}/${fileName}`;

      const { error: uploadErr } = await supabase.storage
        .from(BUCKET)
        .upload(storagePath, buffer, {
          contentType: "image/jpeg",
          upsert: false,
        });

      if (uploadErr) continue;

      const { data: publicUrl } = supabase.storage
        .from(BUCKET)
        .getPublicUrl(storagePath);

      await supabase
        .from(TABLE)
        .update({ supabase_image_url: publicUrl.publicUrl })
        .eq("id", row.id);

      console.log(`âœ… Migrated: ${row.id}`);
    }
  }
}

startWorker();
